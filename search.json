[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSP Lecture Notes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "01_Intro.html",
    "href": "01_Intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "04_FourierTransform.html#example-a-sinusoidal-signal",
    "href": "04_FourierTransform.html#example-a-sinusoidal-signal",
    "title": "2  DTFT and DFT",
    "section": "2.1 Example: a sinusoidal signal",
    "text": "2.1 Example: a sinusoidal signal\nConsider a cosine signal: \\[x(t) = \\cos(2 \\pi f n)\\] with \\(f = 0.01\\)\nThis is how the signal looks like:\n\n# Create the signal\nf = 0.02\nN = 30\n#fmax = fmax * (N-10)/N\nn = np.arange(N)\nx = np.cos(2*np.pi*f*n)\n\n# Plot the signal\nplt.figure(figsize=(6, 3))\nplt.plot(x, '-o')\nplt.title('The signal $x(t) = \\cos(2 \\pi f n)$')\nplt.xlabel('Discrete time $n$')\nplt.ylabel('Signal $x[n]$')\nplt.show()\n\n\n\n\n\n\n\n\nNow let’s compute the Discrete-Time Fourier transform. This assumes that the signal is infinitely long.\nIf the cosine signal would be infinitely long, the DTFT contains only two Dirac impulses at the corresponding frequency.\n\n# Regenerate the signal so that it fits in one period\nperiod = 10000*f\nninf = np.arange(period)\nxinf = np.cos(2*np.pi*f*ninf)\n\n# Compute the DTFT\nSinf = fft(xinf)\n\n# Create the frequency axis\nfreqinf = np.linspace(fmin, fmax, len(Sinf))\n\n# Plot the magnitude of the DTFT\nplt.figure(figsize=(6, 3))\nplt.title('DTFT of infinitely-long periodic signal')\nplt.stem(freqinf, np.abs(Sinf), linefmt='b')\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()\n\n\n\n\n\n\n\n\nIf the signal is assumed to be only the segment we defined, and is surrounded by infinitely-long zeros, i.e. a truncated cosine, then the spectrum is convoluted with the spectrum of a rectangular window, and the DTFT looks as follows:\n\n# Compute the DTFT\nFFT_points = 10000*n.size\nS1 = fft(x, FFT_points)\n\n# Create the frequency axis\nfreq1 = np.linspace(fmin, fmax, len(S1))\n\n# Plot the magnitude of the DTFT\nplt.figure(figsize=(6, 3))\nplt.title('DTFT of windowed signal')\nplt.plot(freq1, np.abs(S1), 'b')\n#plt.stem(freqinf, np.abs(Sinf), 'b')\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()\n\n\n\n\n\n\n\n\nWhen computing the Discrete Fourier Transform (DFT), this assumes that the given piece of the signal is would be repeated periodically. The DFT is not continous, it is discrete.\n\n# Compute the DFT\nS2 = fft(x)\n\n# Create the frequency axis\nfreq2 = np.linspace(fmin, fmax, len(S2))\n#freq2 = np.fft.fftfreq(x.size)\n\n# Plot the magnitude of the DTFT\nplt.figure(figsize=(6, 3))\nplt.title('Its DFT')\nplt.stem(freq2, np.abs(S2), linefmt='ro')\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()\n\n\n\n\n\n\n\n\nThe DFT is just sampled from the DTFT:\n\n# Plot the DTFT and DFT overlaid\nfreq2 = np.linspace(fmin, fmax, len(S2)+1)\nplt.figure(figsize=(6, 3))\nplt.plot(freq1, np.abs(S1), 'b')\nplt.stem(freq2[:-1], np.abs(S2), linefmt='ro')\nplt.title('The DFT is just sampled from the DTFT')\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()"
  },
  {
    "objectID": "04_FourierTransform.html#example-rectangle-pulse",
    "href": "04_FourierTransform.html#example-rectangle-pulse",
    "title": "2  DTFT and DFT",
    "section": "2.2 Example: rectangle pulse",
    "text": "2.2 Example: rectangle pulse\nConsider a rectangle pulse signal as below:\n\n# Create the signal\nlen_1 = 100\nlen_0 = 100\nx = np.hstack((np.ones(len_1), np.zeros(len_1)))\nx = np.hstack((x, x))\n\n# Plot the signal\nplt.figure()\nplt.plot(x)\nplt.xlabel('Discrete time $n$')\nplt.ylabel('Signal $x[n]$')\nplt.show()\n\n\n\n\n\n\n\n\nThe DTFT is:\n\n# Compute the DTFT of the rectangle window\nFFT_points = 2000\nW = fft(x, FFT_points)\n\n# Create the frequency axis\nfreq = np.linspace(fmin, fmax, len(W))\n\n# Plot the magnitude of the DTFT\nplt.figure()\nplt.plot(freq, np.abs(W))\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()"
  },
  {
    "objectID": "Shiny.html",
    "href": "Shiny.html",
    "title": "3  Shinylive in Quarto example",
    "section": "",
    "text": "This is a Shinylive application embedded in a Quarto doc.\n#| standalone: true\n#| viewerHeight: 2000\n# components: [editor, viewer]\n#| components: [viewer]\n#| layout: vertical\n\nfrom shiny import *\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfft = np.fft.fft\nfmin, fmax = 0, 1\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_slider(\"freq\", \"Frequency\", 0, 0.5, 0.1, step=0.001),\n            ui.input_slider(\"N\", \"Length\", 10, 200, 30, step=1),\n        ),\n        ui.panel_main(\n            ui.output_plot(\"plot_signal\"),\n            #ui.output_plot(\"plot_DTFT_per\"),\n            ui.output_plot(\"plot_DTFT_rect\"),\n            ui.output_plot(\"plot_DFT\"),\n            ui.output_plot(\"plot_DTFT_DFT\")\n\n        ),\n    ),)\n\ndef server(input, output, session):\n\n    def prepare():\n        global f, N, n, x\n\n        # Read inputs\n        f = input.freq()\n        N = input.N()\n\n        # Create the signal\n        n = np.arange(N)\n        x = np.cos(2*np.pi*f*n)\n\n    @output\n    @render.plot(alt=\"Sine wave\")\n    def plot_signal():\n        prepare()\n        fig = plt.figure(figsize=(6, 3))\n        plt.plot(x, '-o')\n        plt.title('The signal $x(t) = \\cos(2 \\pi f n)$')\n        plt.xlabel('Discrete time $n$')\n        plt.ylabel('Signal $x[n]$')\n        plt.show()\n\n    @output\n    @render.plot(alt=\"Sine wave\")\n    def plot_DTFT_per():\n        prepare()\n\n        # Regenerate the signal so that it fits in one period\n        period = 1000*f\n        ninf = np.arange(period)\n        xinf = np.cos(2*np.pi*f*ninf)\n\n        # Compute the DTFT\n        Sinf = fft(xinf)\n\n        # Create the frequency axis\n        freqinf = np.linspace(fmin, fmax, len(Sinf))\n\n        # Plot the magnitude of the DTFT\n        plt.figure(figsize=(6, 3))\n        plt.title('DTFT of infinitely-long periodic signal')\n        plt.stem(freqinf, np.abs(Sinf), linefmt='b')\n        plt.xlabel('Frequency')\n        plt.ylabel('Magnitude')\n        plt.show()\n\n    @output\n    @render.plot(alt=\"Sine wave\")\n    def plot_DTFT_rect():\n        prepare()\n\n        # Compute the DTFT\n        FFT_points = 10000*n.size\n        S1 = fft(x, FFT_points)\n\n        # Create the frequency axis\n        freq1 = np.linspace(fmin, fmax, len(S1))\n\n        # Plot the magnitude of the DTFT\n        plt.figure(figsize=(6, 3))\n        plt.title('DTFT of windowed signal')\n        plt.plot(freq1, np.abs(S1), 'b')\n        #plt.stem(freqinf, np.abs(Sinf), 'b')\n        plt.xlabel('Frequency')\n        plt.ylabel('Magnitude')\n        plt.show()\n\n\n    @output\n    @render.plot(alt=\"Sine wave\")\n    def plot_DFT():\n        prepare()\n        \n        # Compute the DFT\n        S2 = fft(x)\n\n        # Create the frequency axis\n        freq2 = np.linspace(fmin, fmax, len(S2))\n        #freq2 = np.fft.fftfreq(x.size)\n\n        # Plot the magnitude of the DFT\n        plt.figure(figsize=(6, 3))\n        plt.title('Its DFT')\n        plt.stem(freq2, np.abs(S2), linefmt='ro')\n        plt.xlabel('Frequency')\n        plt.ylabel('Magnitude')\n        plt.show()\n\n    @output\n    @render.plot(alt=\"Sine wave\")\n    def plot_DTFT_DFT():\n        prepare()\n\n        # Compute the DTFT\n        FFT_points = 10000*n.size\n        S1 = fft(x, FFT_points)\n        freq1 = np.linspace(fmin, fmax, len(S1))\n\n        # Compute the DFT\n        S2 = fft(x)\n\n        # Plot the DTFT and DFT overlaid\n        freq2 = np.linspace(fmin, fmax, len(S2)+1)\n        plt.figure(figsize=(6, 3))\n        plt.plot(freq1, np.abs(S1), 'b')\n        plt.stem(freq2[:-1], np.abs(S2), linefmt='ro')\n        plt.title('The DFT is just sampled from the DTFT')\n        plt.xlabel('Frequency')\n        plt.ylabel('Magnitude')\n        plt.show()        \napp = App(app_ui, server)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Ex01_Sampling.html#exercise-1",
    "href": "Ex01_Sampling.html#exercise-1",
    "title": "4  Exercises 01: Sampling",
    "section": "4.1 Exercise 1",
    "text": "4.1 Exercise 1\nAre the following signals periodic? If yes, compute their period.\n\na). \\(x[n] = \\cos(\\pi \\frac{3}{10} n)\\)\nb). \\(x[n] = \\cos(7.2 \\pi n)\\)\nc). \\(x[n] = \\sin(3n)\\)\nd). \\(x[n] = \\sin(\\frac{\\pi n}{2}) + \\cos(\\frac{3 \\pi n}{4})\\)\n\n\nSolution\na). We want to find the smallest positive integer \\(N\\) such that \\(x[n] = x[n+N]\\), i.e. \\[\\begin{aligned}\n\\cos(\\pi \\frac{3}{10} n) &= \\cos(\\pi \\frac{3}{10} (n+N)) \\\\\n&= \\cos(\\pi \\frac{3}{10} n + \\pi \\frac{3}{10} N) \\\\\n\\end{aligned}\\]\nThis is true if the extraterm \\(\\pi \\frac{3}{10} N\\) is \\(2 \\pi k\\), i.e.: \\[\\begin{aligned}\n\\pi \\frac{3}{10} N &= 2 \\pi k \\\\\n\\frac{3}{10} N &= 2 k \\\\\nN &= \\frac{20}{3} k\n\\end{aligned}\\] with \\(k\\) integer. The smallest positive integer \\(N\\) is \\(N=20\\) (when \\(k=3\\)). Therefore the signal is periodic with period \\(N=20\\).\nb). We want to find the smallest positive integer \\(N\\) such that \\(x[n] = x[n+N]\\), i.e. \\[\\begin{aligned}\n\\cos(7.2 \\pi n) &= \\cos(7.2 \\pi (n+N)) \\\\\n&= \\cos(7.2 \\pi n + 7.2 \\pi N) \\\\\n\\end{aligned}\\]\nThis is true if \\(7.2 \\pi N = 2 \\pi k\\), i.e.: \\[\\begin{aligned}\n7.2 \\pi N &= 2 \\pi k \\\\\n3.6 N &= k \\\\\n\\end{aligned}\\] with \\(k\\) integer. The smallest positive integer \\(N\\) is \\(N=5\\).\nAn alternative way is to to treat this as a continuous signal and identify the frequency of the cosine: \\[\\begin{aligned}\n\\cos(7.2 \\pi n) &= \\cos(2 \\pi f n) \\\\\nf &= 3.6Hz\n\\end{aligned}\\] The period should be \\(N=\\frac{1}{f} = \\frac{1}{3.6} = \\frac{5}{18}\\), but since we need \\(N\\) to be an integer because our signal ia actually discrete, we consider the smallest integer multiple of this, which is: \\[N = \\frac{5}{18} \\cdot 18 = 5\\] Therefore the signal is periodic with period \\(N=5\\).\nc). We want to find the smallest positive integer \\(N\\) such that \\(x[n] = x[n+N]\\), i.e. \\[\\begin{aligned}\n\\sin(3 n) &= \\sin(3 (n+N)) \\\\\n&= \\sin(3 n + 3 N) \\\\\n\\end{aligned}\\]\nThis is true if \\(3 N = 2 \\pi k\\), i.e.: \\[\\begin{aligned}\n3 N &= 2 \\pi k \\\\\nN &= \\frac{2}{3} \\pi k \\\\\n\\end{aligned}\\] with \\(k\\) integer.\nThis is impossible, because \\(k\\) is an irrational number which means that multiplying and dividing it by the integer numbers 2, 3, \\(k\\) will never become an integer as we need \\(N\\) to be.\nTherefore the signal is not periodic.\nd). We want to find the smallest positive integer \\(N\\) such that \\(x[n] = x[n+N]\\), i.e. \\[\\begin{aligned}\n\\sin(\\frac{\\pi n}{2}) + \\cos(\\frac{3 \\pi n}{4}) &= \\sin(\\frac{\\pi}{2} (n+N)) + \\cos(\\frac{3 \\pi}{4} (n+N)) \\\\\n&= \\sin(\\frac{\\pi}{2} n + \\frac{\\pi}{2} N) + \\cos(\\frac{3 \\pi}{4} n + \\frac{3 \\pi}{4} N) \\\\\n\\end{aligned}\\]\nThis is true if \\(\\frac{\\pi}{2} N = 2 \\pi k\\) and \\(\\frac{3 \\pi}{4} N = 2 \\pi k'\\), i.e.: \\[\\begin{aligned}\n\\frac{\\pi}{2} N &= 2 \\pi k \\\\\n\\frac{3 \\pi}{4} N &= 2 \\pi k' \\\\\n\\end{aligned}\\] with \\(k\\), \\(k'\\) being integers.\nThis means: \\[\\begin{aligned}\nN &= 4 k \\\\\nN &= \\frac{8}{3} k' \\\\\n\\end{aligned}\\]\nThe smallest positive integer \\(N\\) is \\(N=8\\) (when \\(k=2\\) and \\(k'=3\\)). Therefore the signal is periodic with period \\(N=8\\)."
  },
  {
    "objectID": "Ex01_Sampling.html#exercise-2",
    "href": "Ex01_Sampling.html#exercise-2",
    "title": "4  Exercises 01: Sampling",
    "section": "4.2 Exercise 2",
    "text": "4.2 Exercise 2\nConsider the following signal: \\[x_a(t) = (1 + 0.5 cos(400 \\pi t)) \\cdot cos(8000 \\pi t)\\]\n\na). Compute the minimum sampling frequency necessary for avoiding alias;\nb). The signal is sampled with 8000Hz. Write the discrete signal obtained via sampling;\nc). Does alias occur? If yes, identify the frequencies in the signal which are aliased;\nd). What is the analog signal reconstructed from the samples via ideal D/A.reconstruction?\n\n\nSolution\na). Compute the minimum sampling frequency necessary for avoiding alias;\nThe minimum sampling frequency necessary for avoiding alias is the double of the maximum frequency in the signal, so we need to identify the maximum frequency in the signal.\nFor this we need to convert the multiplication of the two cosines into a sum of cosines, because a multiplication of two cosines produces a frequency which is higher than the starting frequencies.\nUsing the trigonometric identity: \\[\\begin{aligned}\n\\cos(\\alpha) \\cos(\\beta) &= \\frac{1}{2} \\left( \\cos(\\alpha - \\beta) + \\cos(\\alpha + \\beta) \\right)\n\\end{aligned}\\] we have: \\[\\begin{aligned}\nx_a(t) &= (1 + 0.5 \\cos(400 \\pi t)) \\cdot \\cos(8000 \\pi t) \\\\\n&=\\cos(8000 \\pi t) + 0.5 \\cos(8000 \\pi t) \\cos(400 \\pi t) \\\\\n&=\\cos(8000 \\pi t) + 0.5 \\frac{1}{2} \\left( \\cos(8000 \\pi t - 400 \\pi t) + \\cos(8000 \\pi t + 400 \\pi t) \\right) \\\\\n&=\\cos(8000 \\pi t) + 0.25 \\cos(7600 \\pi t) + 0.25 \\cos(8400 \\pi t) \\\\\n\\end{aligned}\\]\n\n\n\n\n\n\nFrequent error\n\n\n\nIf the signal is already given as a sum of sinusoidal components, we don’t need to do anything else, just leave it as it is.\n\n\nNext, we identify the frequencies in the signal, which are: \\[\\begin{aligned}\nf_1 &= 4000Hz \\\\\nf_2 &= 3800Hz \\\\\nf_3 &= 4200Hz \\\\\n\\end{aligned}\\]\n\n\n\nFrequencies in the signal\n\n\nThe minimum sampling frequency for avoiding alias is therefore twice the maximum frequency, which is \\(f_3 = 4200Hz\\), i.e.: \\[F_{s_{min}} = 2 \\cdot 4200Hz = 8400Hz\\]\nb). The signal is sampled with 8000Hz. Write the discrete signal obtained via sampling;\nSampling the signal amounts to applying the variable transformation \\(t = \\frac{n}{F_s}\\), i.e.: \\[\\begin{aligned}\nx[n] &= x_a(t) \\Big|_{t = \\frac{n}{F_s}} \\\\\n&= \\cos(8000 \\pi \\frac{n}{F_s}) + 0.25 \\cos(7600 \\pi \\frac{n}{F_s}) + 0.25 \\cos(8400 \\pi \\frac{n}{F_s}) \\\\\n&= \\cos(8000 \\pi \\frac{n}{8000}) + 0.25 \\cos(7600 \\pi \\frac{n}{8000}) + 0.25 \\cos(8400 \\pi \\frac{n}{8000}) \\\\\n&= \\cos(\\pi n) + 0.25 \\cos(\\frac{19}{20} \\pi n) + 0.25 \\cos(\\frac{21}{20} \\pi n) \\\\\n\\end{aligned}\\]\nc). Does alias occur? If yes, identify the frequencies in the signal which are aliased;\nThe sampling frequency is \\(F_s = 8000Hz\\), which is lower than required for avoiding alias of the third component. Therefore we expect the third component to be aliased, while the first and second, for which \\(F_s\\) is more than double, are not aliased.\nIndeed, let’s identify the frequencies in the discrete signal obtained: \\[\\begin{aligned}\n\\pi n = 2 \\pi f_1 n \\Rightarrow f_1 &= \\frac{1}{2} = 0.5 \\\\\n\\frac{19}{20} \\pi n = 2 \\pi f_2 n \\Rightarrow f_2 &= \\frac{19}{40} = 0.475 \\\\\n\\frac{21}{20} \\pi n = 2 \\pi f_3 n \\Rightarrow f_3 &= \\frac{21}{40} = 0.525 \\\\\n\\end{aligned}\\]\nWe have \\(f_1 < 0.5\\), \\(f_2 < 0.5\\), which means they are not aliased, and \\(f_3 > 0.5\\), which is aliased. The frequency \\(f_3\\) is aliased to: \\[f_3' = f_3 - 1 = 0.525 - 1 = -0.475 = -\\frac{19}{40}\\] which means that: \\[\\cos(2 \\pi \\frac{21}{40} n) = \\cos(- 2 \\pi \\frac{19}{40} n), \\forall n\\]\nd). What is the analog signal reconstructed from the samples via ideal D/A reconstruction?\nIdeal A/D reconstruction means that we need to apply the inverse variable transformation \\(n = t \\cdot F_s\\), but starting from the aliased frequencies in the signal, if any.\nWith the aliased frequency \\(f_3'\\), the discrete signal is: \\[x[n] = \\cos(\\pi n) + 0.25 \\cos(\\frac{19}{20} \\pi n) + 0.25 \\cos(-\\frac{19}{20} \\pi n)\\]\nThe analog signal reconstructed via ideal D/A reconstruction is: \\[\\begin{aligned}\nx_r(t) &= \\cos(\\pi \\cdot t \\cdot F_s) + 0.25 \\cos(\\frac{19}{20} \\pi \\cdot t \\cdot F_s) + 0.25 \\cos(-\\frac{19}{20} \\pi \\cdot t \\cdot F_s) \\\\\n&= \\cos(8000 \\pi t) + 0.25 \\cos(7600 \\pi t) + 0.25 \\cos(- 7600 \\pi t) \\\\\n&= \\cos(8000 \\pi t) + 0.25 \\cos(7600 \\pi t) + 0.25 \\cos(7600 \\pi t) \\\\\n&= \\cos(8000 \\pi t) + 0.5 \\cos(7600 \\pi t)\n\\end{aligned}\\]\nDue to aliasing, the reconstructed signal is not the same as the original signal."
  },
  {
    "objectID": "Ex02_Systems.html#exercise-1",
    "href": "Ex02_Systems.html#exercise-1",
    "title": "5  Exercises 02: Signals and Systems",
    "section": "5.1 Exercise 1",
    "text": "5.1 Exercise 1\nConsider the following discrete signal \\(x[n]\\): \\[x[n] =\n\\begin{cases}\n1 + \\frac{n}{3}, &-3 \\leq n \\leq -1\\\\\n1, &0 \\leq n \\leq 3\\\\\n0, &\\text{elsewhere}\n\\end{cases}\n\\]\n\n\nFind the values of \\(x[n]\\) and represent the signal graphically\n\n\nRepresent graphically the signal \\(x[-n + 4]\\)\n\n\nWrite the expression of \\(x[n]\\) based on the signal \\(\\delta[n]\\)\n\n\nWrite the expression of \\(x[n]\\) based on the signal \\(u[n]\\)\n\n\n\nSolution\na). Find the values of \\(x[n]\\) and represent the signal graphically\nGiving values for \\(n\\) in the range \\(-3 \\leq n \\leq 3\\), we obtain the following values for \\(x[n]\\): \\[x[n] = \\{..., 0, \\frac{1}{3}, \\frac{2}{3}, \\underuparrow{1}, 1, 1, 1, 0, ...\\}\\] The graphical representation of the signal is:\n\nb). Represent graphically the signal \\(x[-n + 4]\\)\nLet’s give a name to the signal \\(x[-n + 4]\\), say \\(a[n]\\). We have: \\[a[n] = x[-n + 4]\\]\nTo understand visually what this means, let’s compute a few values of \\(a[n]\\): \\[\\begin{aligned}\na[0]=x[-0+4] &= x[4] = 0 \\\\\na[1]=x[-1+4] &= x[3] = 1 \\\\\na[2]=x[-2+4] &= x[2] = 1 \\\\\n\\end{aligned}\\]\nWe have \\(x[4]\\) moving to \\(a[0]\\), \\(x[3]\\) moving to \\(a[1]\\), \\(x[2]\\) moving to \\(a[2]\\), which means that the signal \\(x[n]\\) is reversed and then shifted.\nWe can continue and extend the signal \\(a[n]\\) to the left and to the right, obtaining the full signal \\(a[n]\\): \\[a[n] = \\{..., \\underuparrow{0}, 1, 1, 1, 1, \\frac{2}{3}, \\frac{1}{3}, 0, ...\\}\\]\n\n\n\nThe signal \\(a[n] = x[-n + 4]\\)\n\n\nc). Write the expression of \\(x[n]\\) based on the signal \\(\\delta[n]\\)\nEach Dirac in the graphical representation of \\(x[n]\\), taken separately, is a shifted impulse, having a certain shift and a certain amplitude.\nEach Dirac line located at position \\(k\\) with amplitude \\(A\\) can be written as \\(A \\cdot \\delta[n - k]\\). For example, the Dirac line located at position \\(-2\\) with amplitude \\(\\frac{1}{3}\\) can be written as the signal \\(\\frac{1}{3} \\cdot \\delta[n + 2]\\).\n\nTherefore, we can write any signal as as sum of impulse signals. In this case, we have: \\[x[n] = \\frac{1}{3} \\delta[n + 2] + \\frac{2}{3} \\delta[n + 1] + \\delta[n] + \\delta[n - 1] + \\delta[n - 2] + \\delta[n - 3]\\]\nd). Write the expression of \\(x[n]\\) based on the signal \\(u[n]\\)\nThere are two ways to write the signal \\(x[n]\\) based on the signal \\(u[n]\\).\nIn the first method, note that we can write any impulse signal as a difference of two step signals, the second one being one step delayed with resoect to the first. For example, the signal \\(\\delta[n]\\) can be written as \\(u[n] - u[n-1]\\), as illustrated in the following figure:\n\n\n\nThe signal \\(\\delta[n]\\) as a difference of two step signals\n\n\nTherefore we can start from the sum of impulses and write each impulse as a difference of two step signals: \\[\\begin{aligned}\nx[n] &= \\frac{1}{3} \\delta[n + 2] + \\frac{2}{3} \\delta[n + 1] + \\delta[n] + \\delta[n - 1] + \\delta[n - 2] + \\delta[n - 3] \\\\\n&= \\frac{1}{3} (u[n + 2] - u[n + 1]) + \\frac{2}{3} (u[n + 1] - u[n]) + (u[n] - u[n - 1]) + (u[n - 1] - u[n - 2]) + (u[n - 2] - u[n - 3]) + (u[n - 3] - u[n-4]) \\\\\n&= \\frac{1}{3} u[n + 2] + \\frac{1}{3} u[n + 1] + \\frac{1}{3}u[n] - u[n - 4]\n\\end{aligned}\\]\nA second, more visually intuitive way, relies on visually decomposing the signal \\(x[n]\\) into a sum of step signals. Observe the figure below and how we can decompose the signal \\(x[n]\\) as a staircase with several steps:\n\n\n\nThe signal \\(x[n]\\) as a sum of step signals\n\n\n\nThe first step starts at \\(n = -2\\) and has a height of \\(\\frac{1}{3}\\), so it can be written as \\(\\frac{1}{3} u[n + 2]\\)\nOn top of this we have a second step starting at \\(n = -1\\) and having a height of \\(\\frac{1}{3}\\), so it can be written as \\(\\frac{1}{3} u[n + 1]\\)\nOn top of these we have a third step starting at \\(n = 0\\) and having a height of \\(\\frac{1}{3}\\), so it can be written as \\(\\frac{1}{3} u[n]\\)\nOn top of these we have a fourth negative step starting at \\(n = 4\\) and having a height of \\(-1\\), so it can be written as \\(-u[n - 4]\\). This one will cancel all the first three, from this point onwards.\n\nThe result can therefore be written as: \\[x[n] = \\frac{1}{3} u[n + 2] + \\frac{1}{3} u[n + 1] + \\frac{1}{3}u[n] - u[n - 4]\\]"
  },
  {
    "objectID": "Ex02_Systems.html#exercise-2",
    "href": "Ex02_Systems.html#exercise-2",
    "title": "5  Exercises 02: Signals and Systems",
    "section": "5.2 Exercise 2",
    "text": "5.2 Exercise 2\nConsider the following signal: \\[x[n] =\n\\begin{cases}\n1, &-1 \\leq n \\leq 2\\\\\n\\frac{1}{2}, &3 \\leq n \\leq 4\\\\\n0, &elsewhere\n\\end{cases}\n\\]\nRepresent graphically the following signals:\n\na). \\(x[n-2]\\)\nb). \\(x[n+2]\\)\nc). \\(x[4-n]\\)\nd). \\(x[n] \\cdot u[2-n]\\)\ne). \\(x[n-1] \\cdot \\delta[n-3]\\)\nf). \\(x[n^2]\\)\ng). The even part of \\(x[n]\\)\nh). The odd part of \\(x[n]\\)\n\n\nSolution\nThat’s way too much drawing for me, so I’ll just write in words what needs to be done.\na). \\(x[n-2]\\)\nThis is the signal \\(x[n]\\) shifted to the right by 2 steps (i.e. shifted to the future).\nb). \\(x[n+2]\\)\nThis is the signal \\(x[n]\\) shifted to the left by 2 steps (i.e. shifted to the past).\nc). \\(x[4-n]\\)\nDo this just like in Exercise 1.\nd). \\(x[n] \\cdot u[2-n]\\)\nThis is the signal \\(x[n]\\) multiplied by the signal \\(u[2-n]\\).\nDraw first the signal \\(u[2-n]\\), like in Exercise 1. This is a step signal (\\(u[n]\\)) that starts at \\(n = 2\\) and goes towards the left with 1’s (is reversed), and has 0’s towards the right.\nThen, multiply the two signals, point by point. The right part of the signal \\(x[n]\\) will be multiplied by 0’s, so it will vanish, while the left part of the signal \\(x[n]\\) will be multiplied by 1’s, so it will remain.\ne). \\(x[n-1] \\cdot \\delta[n-3]\\)\nThis is the signal \\(x[n-1]\\) multiplied by the signal \\(\\delta[n-3]\\).\nThe signal \\(\\delta[n-3]\\) is a shifted impulse, located at \\(n = 3\\). Therefore it has a single value of 1 at position \\(n = 3\\), and 0’s everywhere else.\nMultiplication with \\(x[n-1]\\) will produce a signal that is 0 everywhere, except at position \\(n = 3\\), where it will have the value of \\(x[n-1]\\) at that position, which should be \\(x[2] = 1\\).\nf). \\(x[n^2]\\)\nGive this signal a new name and compute its values for all \\(n\\), like in Exercise 1. \\[a[n] = x[n^2]\\] \\[a[0] = x[0^2] = x[0] = 1\\] \\[a[1] = x[1^2] = x[1] = 1\\] \\[a[-1] = x[(-1)^2] = x[1] = 1\\] \\[...\\]\ng). The even part of \\(x[n]\\)\nThe even part of a signal is defined as (see Lectures): \\[x_e[n] = \\frac{1}{2} (x[n] + x[-n])\\]\nThe signal \\(x[-n]\\) is the signal \\(x[n]\\) reversed (horizontal flip). Compute the values of \\(x_e[n]\\) for all \\(n\\), one by one, according to this definition.\nh). The odd part of \\(x[n]\\)\nThe odd part of a signal is defined as (see Lectures): \\[x_o[n] = \\frac{1}{2} (x[n] - x[-n])\\]\nThe signal \\(x[-n]\\) is the signal \\(x[n]\\) reversed (horizontal flip). Compute the values of \\(x_o[n]\\) for all \\(n\\), one by one, according to this definition."
  },
  {
    "objectID": "Ex02_Systems.html#exercise-3",
    "href": "Ex02_Systems.html#exercise-3",
    "title": "5  Exercises 02: Signals and Systems",
    "section": "5.3 Exercise 3",
    "text": "5.3 Exercise 3\nCharacterize the following systems with respect to:\n\nMemory\nLinearity\nTime invariance\nCausality\nStability\n\nThe systems are:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nb). \\(y[n] = x[n] \\cdot cos(\\omega_0 n)\\)\nc). \\(y[n] = \\sin(x[n])\\)\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\n\n\nSolution\nLet us consider each property in turn.\n\nMemory\nA system is memoryless if the output at time \\(n\\) depends only on the input at time \\(n\\). This means \\(y[n]\\) depends only on \\(x[n]\\), for any \\(n\\), without any delays (no \\(x[n-1]\\), \\(x[n+1]\\) etc).\nOtherwise, the system has memory.\nLet’s see the systems one by one:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nHas memory, because, for example, \\(y[2] = 2 x[4]\\), so it depends on \\(x[4]\\), not just on \\(x[2]\\).\nb). \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\)\nIs memoryless, because \\(y[2] = x[2] \\cdot \\cos(\\omega_0 \\cdot 2)\\), \\(y[3] = x[3] \\cdot \\cos(\\omega_0 \\cdot 3)\\), etc. so every \\(y[n]\\) depends only on \\(x[n]\\) and never on \\(x[n-1]\\), \\(x[n+1]\\) etc.\nc). \\(y[n] = \\sin(x[n])\\)\nIs memoryless, because \\(y[2] = \\sin(x[2])\\), \\(y[3] = \\sin(x[3])\\), etc. so every \\(y[n]\\) depends only on \\(x[n]\\) and never on \\(x[n-1]\\), \\(x[n+1]\\) etc.\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\nHas memory because \\(y[n]\\) depends on \\(x[n+1]\\), according to the second term.\n\n\n\nLinearity\nA system is linear if it satisfies the superposition principle, i.e. if the output of the sum of two inputs is equal to the sum of the outputs of the two inputs taken separately. \\[\\mathcal{H}\\left\\{a_1 x_1[n] + a_2 x_2[n]\\right\\} = a_1 \\mathcal{H}\\left\\{x_1[n]\\right\\} + a_2 \\mathcal{H}\\left\\{x_2[n]\\right\\}\\]\nThis means that if we replace \\(x[n]\\) with \\(a_1 x_1[n] + a_2 x_2[n]\\) in the equation, we obtain the same result as if we would have applied the system to \\(x_1[n]\\) and \\(x_2[n]\\) separately and then added the results.\nLet’s see the systems one by one:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nIs linear, because:\n\nwith \\(x_1[n]\\) we have \\(\\mathcal{H}\\left\\{x_1[n]\\right\\} = n \\cdot x_1[n^2]\\)\nwith \\(x_2[n]\\) we have \\(\\mathcal{H}\\left\\{x_2[n]\\right\\} = n \\cdot x_2[n^2]\\)\nwith \\(a x_1[n] + b x_2[n]\\) we have:\n\\[\\begin{aligned}\n\\mathcal{H}\\left\\{a x_1[n] + b x_2[n]\\right\\} &=\nn \\cdot (a x_1[n^2] + b x_2[n^2]) \\\\\n&= a n \\cdot x_1[n^2] + b n \\cdot x_2[n^2] \\\\\n&= a \\mathcal{H}\\left\\{x_1[n]\\right\\} + b \\mathcal{H}\\left\\{x_2[n]\\right\\}\n\\end{aligned}\\]\nNote that it’s not the signal \\(x[n]\\) which is raised to power, but the index \\(n\\). The signal \\(x[n]\\) does therefore not undergo any nonlinear operation.\n\nb). \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\)\nIs linear, because:\n\nwith \\(x_1[n]\\) we have \\(\\mathcal{H}\\left\\{x_1[n]\\right\\} = x_1[n] \\cdot \\cos(\\omega_0 n)\\)\nwith \\(x_2[n]\\) we have \\(\\mathcal{H}\\left\\{x_2[n]\\right\\} = x_2[n] \\cdot \\cos(\\omega_0 n)\\)\nwith \\(a x_1[n] + b x_2[n]\\) we have:\n\\[\\begin{aligned}\n\\mathcal{H}\\left\\{a x_1[n] + b x_2[n]\\right\\} &=\n(a x_1[n] + b x_2[n]) \\cdot \\cos(\\omega_0 n) \\\\\n&= a x_1[n] \\cdot \\cos(\\omega_0 n) + b x_2[n] \\cdot \\cos(\\omega_0 n) \\\\\n&= a \\mathcal{H}\\left\\{x_1[n]\\right\\} + b \\mathcal{H}\\left\\{x_2[n]\\right\\}\n\\end{aligned}\\]\n\nc). \\(y[n] = \\sin(x[n])\\)\nIs not linear, because:\n\nwith \\(x_1[n]\\) we have \\(\\mathcal{H}\\left\\{x_1[n]\\right\\} = \\sin(x_1[n])\\)\nwith \\(x_2[n]\\) we have \\(\\mathcal{H}\\left\\{x_2[n]\\right\\} = \\sin(x_2[n])\\)\nwith \\(a x_1[n] + b x_2[n]\\) we have:\n\\[\\begin{aligned}\n\\mathcal{H}\\left\\{a x_1[n] + b x_2[n]\\right\\} &=\n\\sin(a x_1[n] + b x_2[n]) \\\\\n&\\neq a \\sin(x_1[n]) + b \\sin(x_2[n]) \\\\\n&= a \\mathcal{H}\\left\\{x_1[n]\\right\\} + b \\mathcal{H}\\left\\{x_2[n]\\right\\}\n\\end{aligned}\\]\nThis is not equal to the sum of the previous two.\n\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\nIs linear, because:\n\nwith \\(x_1[n]\\) we have \\(\\mathcal{H}\\left\\{x_1[n]\\right\\} = x_1[n] + n \\cdot x_1[n+1]\\)\nwith \\(x_2[n]\\) we have \\(\\mathcal{H}\\left\\{x_2[n]\\right\\} = x_2[n] + n \\cdot x_2[n+1]\\)\nwith \\(a x_1[n] + b x_2[n]\\) we have:\n\\[\\begin{aligned}\n\\mathcal{H}\\left\\{a x_1[n] + b x_2[n]\\right\\} &=\n(a x_1[n] + b x_2[n]) + n \\cdot (a x_1[n+1] + b x_2[n+1]) \\\\\n&= a x_1[n] + a n \\cdot x_1[n+1] + b x_2[n] + b n \\cdot x_2[n+1] \\\\\n&= a \\mathcal{H}\\left\\{x_1[n]\\right\\} + b \\mathcal{H}\\left\\{x_2[n]\\right\\}\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\nQuick way of checking linearity\n\n\n\nTo be linear, any signal which appears in the equation (\\(x[n]\\), \\(x[n-1]\\), \\(y[n]\\) etc.) should not undergo any nonlinear operation, such as raising to power, trigonometric functions etc. Any such operation will make the system nonlinear, because for example: \\[sin(x_1[n] + x_2[n]) \\neq \\sin(x_1[n]) + \\sin(x_2[n])\\] \\[(x_1[n] + x_2[n])^2 \\neq x_1[n]^2 + x_2[n]^2\\] \\[...\\]\nThe only operations allowed which preserve linearity are:\n\nmultiplication by something which is not a signal (i.e. \\(x[n] \\cdot x[n+1]\\) is not linear, but \\(x[n] \\cdot 3\\) is linear, \\(x[n] \\cdot \\cos(\\omega_0 n)\\) is linear)\ndelay (shift) by a constant, i.e. \\(x[n+3]\\), \\(y[n-1]\\) etc.\nsums between the above\n\n\n\n\n\nTime invariance\nA system is time-invariant if a time shift in the input signal, \\(x[n-k]\\), produces a corresponding time shift in the output signal, but no other change, i.e.: \\[\\mathcal{H}\\left\\{x[n - k]\\right\\} = y[n - k]\\]\nLet’s see the systems one by one:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nIs not time-invariant, because:\n\nwith \\(x[n-k]\\) we have \\(\\mathcal{H}\\left\\{x[n-k]\\right\\} = n \\cdot x[(n-k)^2]\\)\ndelaying the output by \\(k\\) we have \\(y[n-k] = (n-k) \\cdot x[(n-k)^2]\\)\nthey are not the same\n\nb). \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\)\nIs not time-invariant, because:\n\nwith \\(x[n-k]\\) we have \\(\\mathcal{H}\\left\\{x[n-k]\\right\\} = x[n-k] \\cdot \\cos(\\omega_0 n)\\)\ndelaying the output by \\(k\\) we have \\(y[n-k] = x[n-k] \\cdot \\cos(\\omega_0 (n-k))\\)\nthey are not the same\n\nc). \\(y[n] = \\sin(x[n])\\)\nIs time-invariant, because:\n\nwith \\(x[n-k]\\) we have \\(\\mathcal{H}\\left\\{x[n-k]\\right\\} = \\sin(x[n-k])\\)\ndelaying the output by \\(k\\) we have \\(y[n-k] = \\sin(x[n-k])\\)\nthey are the same\n\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\nIs not time-invariant, because:\n\nwith \\(x[n-k]\\) we have \\(\\mathcal{H}\\left\\{x[n-k]\\right\\} = x[n-k] + n \\cdot x[(n-k)+1]\\)\ndelaying the output by \\(k\\) we have \\(y[n-k] = x[n-k] + (n-k) \\cdot x[(n-k)+1]\\)\nthey are not the same\n\n\n\n\n\n\n\n\nQuick way of checking time invariance\n\n\n\nTo be time invariant, there should be no \\(n\\) outside the signals \\(x[n]\\), \\(x[n-1]\\), \\(y[n]\\), \\(y[n-1]\\) etc.\nIf there is any \\(n\\) outside the signals, then the system depends on absolute time, and is therefore not time invariant.\nExamples:\n\n\\(y[n] = x[n] + n \\cdot x[n+1]\\) is not time invariant, because of the \\(n\\) outside the signals\n\\(y[n] = \\sin(x[n])\\) is time invariant, because there is no \\(n\\) outside the signals, only within parantheses of \\(x[n]\\)\n\n\n\n\n\nCausality\nA system is causal if the output at time \\(n\\) depends only on the input at time \\(n\\) and in the past, i.e. \\(x[n-k]\\), but never on the future, i.e. \\(x[n+1]\\).\nLet’s see the systems one by one:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nIs not causal, because \\(y[2] = 2 x[4]\\), so \\(y[2]\\) depends on \\(x[4]\\) which is in the future.\nb). \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\)\nIs causal, because \\(y[2] = x[2] \\cdot \\cos(\\omega_0 \\cdot 2)\\), \\(y[3] = x[3] \\cdot \\cos(\\omega_0 \\cdot 3)\\), etc. so every \\(y[n]\\) depends only on \\(x[n]\\) and never on the future.\nc). \\(y[n] = \\sin(x[n])\\)\nIs causal, because \\(y[2] = \\sin(x[2])\\) etc. so every \\(y[n]\\) depends only on \\(x[n]\\) and never on the future.\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\nIs not causal, because \\(y[n]\\) depends on \\(x[n+1]\\), so it depends on the future.\n\n\n\nStability\nA system is stable if the output is bounded for any bounded input. This means that if the input is not going to infinity, then the output must not go to infinity either.\n(Bounded = it does not go to infinity)\nThis is a bit more difficult to check. Basically we look for counterexamples, i.e. when the inputs are bounded (like the unit step 1, 1, 1, 1, … ) but the output goes to infinity. If we can’t find any counterexample, we must find an argument showing that the output never goes to infinity.\nLet’s see the systems one by one:\n\na). \\(y[n] = n \\cdot x[n^2]\\)\nIs not stable because of \\(n\\).\nAssume that the input is \\(x[n] = 1, 1, 1, 1, ...\\). Let’s compute some outputs: \\[y[1] = 1 \\cdot x[1^2] = 1\\] \\[y[100] = 100 \\cdot x[100^2] = 100\\] \\[y[1000000] = 1000000\\]\nEven though the input is always \\(1\\), when \\(n \\to \\infty\\), the output goes to infinity because of \\(n\\).\nb). \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\)\nIs stable, because:\n\n\\(\\cos(\\omega_0 n)\\) is always between -1 and 1\n\\(x[n]\\) is bounded$\nso the output \\(y[n] = x[n] \\cdot \\cos(\\omega_0 n)\\) is always bounded if \\(x[n]\\) is bounded.\n\nc). \\(y[n] = \\sin(x[n])\\)\nIs stable, because the values of a \\(\\sin\\) are always between -1 and 1, no matter what the input is.\nd). \\(y[n] = x[n] + n \\cdot x[n+1]\\)\nIs not stable because of \\(n\\), same argument as in a)."
  },
  {
    "objectID": "Ex02_Systems.html#exercise-4",
    "href": "Ex02_Systems.html#exercise-4",
    "title": "5  Exercises 02: Signals and Systems",
    "section": "5.4 Exercise 4",
    "text": "5.4 Exercise 4\nCompute the convolution of the signals: \\(x_1[n] = \\{ ...,0,1,2,\\underuparrow{3},4,0,...\\}\\) and \\(x_2[n] = \\{...,0,2,\\underuparrow{2},3,3,0,...\\}\\)\n\nSolution\nThere are three ways of computing the convolution of short signals like these ones.\n\n5.4.0.1 Method 1: using linearity and time invariance\nEach individual value from one signal triggers a copy of the other signal, having the same amplitude and shift as the trigger value.\n\n\n\nConvolution using linearity and time invariance\n\n\n\nthe first value from \\(x_1[n]\\), which is \\(1\\), triggers a copy of \\(x_2[n]\\) multipled by \\(1\\)\nthe second value from \\(x_1[n]\\), which is \\(2\\) and shifted by one step, triggers a copy of \\(x_2[n]\\) multipled by \\(2\\) and shifted by one step\nthe third value from \\(x_1[n]\\), which is \\(3\\) and shifted by two steps, triggers a copy of \\(x_2[n]\\) multipled by \\(3\\) and shifted by two steps\nthe fourth value from \\(x_1[n]\\), which is \\(4\\) and shifted by three steps, triggers a copy of \\(x_2[n]\\) multipled by \\(4\\) and shifted by three steps\n\nThe convolution result is the sum of all these copies, which is: \\[y[n] = \\{..., 2, 6, 13, \\underuparrow{23}, 23, 21, 12, ... \\}\\]\nThe origin of time in the resulting sequence is at the value which corresponds to the origin of time in the two input sequences (see the light blue arrows).\n\n\n5.4.0.2 Method 2: using the definition\nThe convolution of two signals is defined as: \\[y[n] = \\sum_{k=-\\infty}^{\\infty} x_1[k] \\cdot x_2[n-k]\\]\n\n\\(x_1[k]\\) is the first signal\n\\(x_2[n-k]\\) is the second signal, reversed and then shifted by \\(n\\) steps to the right\nfor every shift \\(n\\), multiply these two and sum\n\nWe write \\(x_1[k]\\) once, and then we write all the shifted and reversed copies of \\(x_2[n-k]\\), we multiply them point by point with \\(x_1[k]\\) and sum the result. In this way we compute all the values \\(y[n]\\), one by one.\nThe origin of time in \\(y[n]\\) corresponds to the value calculated when the time origins of the two signals are aligned.\n\n\n\nConvolution using the definition\n\n\n\n\n\n5.4.1 Method 3: using the Z transform (polynomials)\nWe can write the convolution as a product of the Z transforms of the two signals: \\[x_1[n] \\leftrightarrow X_1(z) = 1z^2 + 2z^1 + 3 + 4z^{-1}\\] \\[x_2[n] \\leftrightarrow X_2(z) = 2z^1 + 2 + 3z^{-1} + 3z^{-2}\\] \\[\\begin{aligned}\nx_1[n] \\ast x_2[n] \\leftrightarrow X_1 \\cdot X_2(z) &= (1z^2 + 2z^1 + 3 + 4z^{-1}) \\cdot (2z^1 + 2 + 3z^{-1} + 3z^{-2}) \\\\\n&= 2z^3 + 6z^2 + 13z + 23 + 23z^{-1} + 21z^{-2} + 12z^{-3}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "Ex02_Systems.html#exercise-5",
    "href": "Ex02_Systems.html#exercise-5",
    "title": "5  Exercises 02: Signals and Systems",
    "section": "5.5 Exercise 5",
    "text": "5.5 Exercise 5\nCompute the 2D convolution of the image \\[I = \\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n2 & 2 & 2 & 2 & 2 \\\\\n3 & 3 & 3 & 3 & 3 \\\\\n\\end{bmatrix}\\] with the kernel image: \\[H = \\begin{bmatrix}\n0 & 1 & 0 \\\\\n1 & -4 & 1 \\\\\n0 & 1 & 0 \\\\\n\\end{bmatrix}\\]\nNote: the result must be the same shape as the input signal.\n\nSolution\nWe proceed similarly to Method 2 in the previous exercise.\nWe write the input matrix \\(I\\) once, then reverse \\(H\\) (flip horizontally and vertically), then we shift \\(H\\) across all the positions of \\(I\\), multiply point by point and sum.\nHere, because \\(H\\) is symmetric, flipping it horizontally and vertically makes no difference.\nThe resulting matrix is: \\[\\begin{bmatrix}\n-1 & 0 & 0 & 0 & -1 \\\\\n-2 & 0 & 0 & 0 & -2 \\\\\n-7 & -4 & -4 & -4 & -7 \\\\\n\\end{bmatrix}\\]\n\n\n\n2D convolution"
  }
]